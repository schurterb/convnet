### Second round of tests on gpu improvement ###
Changed learning system to load all necessary training examples to memory
 and then reference them from there.

### GPU test results ###

Layers: 3
Filters per layer: 5
Filter size: 3

Trained with ADAM
for 100 batches
with 10 examples per batch

Training times:

Using GPU 1, gpu_from_host(), and Out(:, borrow=True):
Note - a missing input error prevented use of In on function inputs
Note - used mini-batches here
initialization = 10.71 sec
total_training time  = 210.79 sec
sampling time = 140.07 sec
init time = 25.97 sec
theano train_model function = 44.48 sec


Using GPU 1, gpu_from_host(), Out(:, borrow=True), and fast_math:
Note - a missing input error prevented use of In on function inputs
Note - used mini-batches here
Note - example loading moved to init phase
initialization = 176.12 sec
total_training time  = 45.22 sec
theano train_model function = 44.97 sec



